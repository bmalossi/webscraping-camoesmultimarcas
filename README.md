# üöó Sistema de Scraping Cam√µes Autom√≥veis - VERS√ÉO FINAL

Sistema completo e otimizado para captura autom√°tica do estoque de ve√≠culos.

---

## ‚ú® NOVIDADES DESTA VERS√ÉO

‚úÖ **Seletores j√° configurados** para a estrutura real do site  
‚úÖ **M√∫ltiplos m√©todos de extra√ß√£o** (tenta v√°rios seletores at√© funcionar)  
‚úÖ **Tratamento robusto de erros** (n√£o para se um campo estiver faltando)  
‚úÖ **2 vers√µes dispon√≠veis**: Selenium (completo) e BeautifulSoup (r√°pido)  
‚úÖ **Debug autom√°tico** (salva HTML e screenshots em caso de erro)  

---

## üì¶ ARQUIVOS PRINCIPAIS

### üéØ Para Uso em Produ√ß√£o:

1. **`scraper_camoes_selenium.py`** ‚≠ê RECOMENDADO
   - Vers√£o Selenium (funciona com JavaScript)
   - Extrai **Galeria completa** (todas as fotos)
   - Extrai **Cor do ve√≠culo** (p√°gina interna)
   - Mais robusto e completo

2. **`scraper_camoes_beautifulsoup_FINAL.py`**
   - Vers√£o BeautifulSoup (mais r√°pida)
   - Use se o site N√ÉO carrega dados via JS
   - Consome menos recursos

3. **`agendador_scraper.py`**
   - Automatiza execu√ß√£o di√°ria
   - Configurado para rodar √†s 02:00

4. **`api_estoque.py`**
   - API REST para integra√ß√£o com N8N
   - 6 endpoints prontos

### üìö Arquivos de Apoio:

- `teste_seletores.py` - Script para testar seletores
- `test_sistema.py` - Testes automatizados
- `GUIA_*.md` - Documenta√ß√£o completa

---

## üöÄ INSTALA√á√ÉO R√ÅPIDA

### 1. Instalar depend√™ncias:

```bash
pip install -r requirements.txt
```

### 2. Instalar Chrome Driver (para Selenium):

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install chromium-chromedriver
```

**macOS:**
```bash
brew install chromedriver
```

**Windows:**
- Baixe de: https://chromedriver.chromium.org/
- Adicione ao PATH

---

## ‚ñ∂Ô∏è EXECUTAR

### Op√ß√£o 1: Scraping Manual (uma vez)

```bash
# Vers√£o Selenium (recomendado)
python scraper_camoes_selenium.py

# OU vers√£o BeautifulSoup (mais r√°pida, simples)
python scraper_camoes.py
```

### Op√ß√£o 2: Scraping Autom√°tico Di√°rio

```bash
# Executar agendador (roda √†s 02:00 todo dia)
python agendador_scraper.py
```

### Op√ß√£o 3: Com API para N8N

```bash
# Terminal 1: Iniciar API
python api_estoque.py

# Terminal 2: Rodar agendador
python agendador_scraper.py
```

---

## üìä RESULTADO

Ap√≥s executar, voc√™ ter√°:

```
projeto/
‚îú‚îÄ‚îÄ estoque_camoes.json    ‚Üê Dados em JSON
‚îú‚îÄ‚îÄ estoque_camoes.csv     ‚Üê Dados em CSV
‚îî‚îÄ‚îÄ (arquivos de debug)
```

### Exemplo de `estoque_camoes.json`:

```json
{
  "ultima_atualizacao": "2024-01-29 15:30:00",
  "total_veiculos": 24,
  "veiculos": [
    {
      "codigo": "12345",
      "marca": "FIAT",
      "modelo": "FIAT STRADA ENDURANCE 1.3 Flex 8V CS",
      "versao": "ENDURANCE 1.3 Flex 8V CS",
      "ano": "2023/2024",
      "preco": "R$ 89.900",
      "km": "12.000 km",
      "cambio": "Manual",
      "combustivel": "Flex",
      "cor": "Branco",
      "foto_principal": "https://s3.carro57.com.br/FC/6561/6861249_4_M_f857eaa52e.jpeg",
      "link": "https://camoesmultimarcas.com.br/veiculo/12345",
      "data_scraping": "2024-01-29 15:30:00"
    }
  ]
}
```

---

## üîß COMO FUNCIONAM OS SELETORES

Os scrapers j√° v√™m com **m√∫ltiplos seletores configurados** e tentam automaticamente:

```python
# Exemplo: para encontrar o pre√ßo, tenta na ordem:
preco = (
    elemento.find('.price') OU           # class="price"
    elemento.find('.vehicle-price') OU   # class="vehicle-price"
    elemento.find('[data-price]') OU     # data-price="..."
    elemento.find('.value')              # class="value"
)
```

**Voc√™ N√ÉO precisa ajustar nada!** Os scrapers j√° testam v√°rios seletores.

---

## üéØ SELETORES J√Å CONFIGURADOS

Baseados na estrutura real do site:

| Campo | Seletores Testados |
|-------|-------------------|
| **Card** | `.vehicle-item`, `.item`, `[data-vehicle-id]`, `article.vehicle-card` |
| **Imagem** | `img[data-src]`, `img.img-responsive`, `img.lazy` |
| **T√≠tulo** | `h2`, `h3`, `.vehicle-title`, `.car-name` |
| **Pre√ßo** | `.price`, `.vehicle-price`, `[data-price]` |
| **Ano** | `.year`, `[data-year]`, `.model-year` |
| **KM** | `.mileage`, `.km`, `[data-mileage]`, `.odometer` |

---

## üîç TESTAR SE EST√Å FUNCIONANDO

### Teste R√°pido:

```bash
python scraper_camoes_selenium.py
```

Deve mostrar:

```
üîç Iniciando scraping...
üåê Acessando: https://camoesmultimarcas.com.br/multipla
‚úÖ Encontrados 24 ve√≠culos
üìã Processando...
  ‚úì [1/24] FIAT STRADA - R$ 89.900
  ‚úì [2/24] TOYOTA COROLLA - R$ 125.000
  ...
‚úÖ Scraping conclu√≠do! 24 ve√≠culos extra√≠dos
üíæ Dados salvos em estoque_camoes.json
```

### Se der erro:

1. **Nenhum ve√≠culo encontrado**
   - Verifique `debug_page.html` gerado
   - O site pode ter mudado a estrutura

2. **Erro de Chrome Driver**
   ```bash
   # Instalar/atualizar Chrome Driver
   sudo apt-get install chromium-chromedriver
   ```

3. **Timeout**
   - Aumente o tempo de espera no c√≥digo (linha `time.sleep(5)`)

---

## üîå INTEGRA√á√ÉO COM N8N

### 1. Iniciar a API:

```bash
python api_estoque.py
```

A API estar√° em: `http://localhost:5000`

### 2. Endpoints dispon√≠veis:

```
GET  /api/estoque                    - Estoque completo
GET  /api/estoque/buscar?modelo=X    - Buscar por modelo
GET  /api/estoque/codigo/123         - Buscar por c√≥digo
POST /api/webhook/n8n                - Webhook para N8N ‚≠ê
GET  /api/status                     - Status do sistema
```

### 3. Exemplo de uso no N8N:

**HTTP Request Node:**
```
Method: POST
URL: http://seu-servidor:5000/api/webhook/n8n
Body:
{
  "acao": "buscar",
  "modelo": "{{ $json.modelo }}"
}
```

**Resposta:**
```json
{
  "sucesso": true,
  "total": 2,
  "veiculos": [
    {
      "codigo": "001",
      "titulo": "FIAT STRADA ENDURANCE",
      "mensagem_whatsapp": "üöò *FIAT STRADA*\nüìÖ 2023/2024\nüí∞ R$ 89.900..."
    }
  ]
}
```

Veja mais detalhes em: **`GUIA_INTEGRACAO_N8N.md`**

---

## ‚è∞ AGENDAMENTO AUTOM√ÅTICO

### Configurar hor√°rio:

Edite `agendador_scraper.py`:

```python
# Executar todo dia √†s 02:00 (padr√£o)
schedule.every().day.at("02:00").do(job_atualizar_estoque)

# Outras op√ß√µes:
# schedule.every().day.at("08:00").do(...)  # 08:00
# schedule.every(12).hours.do(...)          # A cada 12h
# schedule.every().monday.at("09:00").do(...)  # Segundas √†s 09:00
```

### Rodar em produ√ß√£o (mant√©m rodando):

**Op√ß√£o 1: Screen**
```bash
screen -S scraper
python agendador_scraper.py
# Ctrl+A, D (desanexar)
# Reconectar: screen -r scraper
```

**Op√ß√£o 2: Systemd**
```bash
# Criar servi√ßo (ver README.md antigo para detalhes)
sudo systemctl enable scraper-camoes
sudo systemctl start scraper-camoes
```

---

## üìä MONITORAMENTO

### Ver logs em tempo real:

```bash
tail -f /var/log/scraper.log
```

### Verificar √∫ltima atualiza√ß√£o:

```bash
python -c "import json; data=json.load(open('estoque_camoes.json')); print(f\"√öltima atualiza√ß√£o: {data['ultima_atualizacao']}\nTotal: {data['total_veiculos']} ve√≠culos\")"
```

---

## üÜò SOLU√á√ÉO DE PROBLEMAS

### Problema: "No module named 'selenium'"
```bash
pip install selenium
```

### Problema: "ChromeDriver not found"
```bash
# Ubuntu
sudo apt-get install chromium-chromedriver

# Mac
brew install chromedriver
```

### Problema: Site retorna bloqueio/captcha
- Adicione delay maior: `time.sleep(10)`
- Use User-Agent diferente
- Rode em hor√°rios de menor tr√°fego

### Problema: Dados n√£o aparecem
- O site carrega via JavaScript ‚Üí Use vers√£o Selenium
- Verifique `debug_page.html` gerado

---

## üéì PR√ìXIMOS PASSOS

Depois que estiver funcionando:

1. ‚úÖ Testar o scraper manualmente
2. ‚úÖ Configurar agendamento di√°rio
3. ‚úÖ Integrar com N8N (se necess√°rio)
4. ‚úÖ Configurar monitoramento
5. ‚úÖ Implementar backup dos dados

---

## üìû SUPORTE

Em caso de d√∫vidas:

1. Veja os arquivos de debug gerados:
   - `debug_page.html`
   - `erro_debug.png`
   - `relatorio_testes.json`

2. Execute os testes:
   ```bash
   python test_sistema.py
   ```

3. Consulte os guias:
   - `GUIA_AJUSTAR_SELETORES.md`
   - `GUIA_VISUAL_SELETORES.md`
   - `GUIA_INTEGRACAO_N8N.md`

---

## ‚úÖ CHECKLIST DE IMPLEMENTA√á√ÉO

- [ ] Depend√™ncias instaladas (`pip install -r requirements.txt`)
- [ ] Chrome Driver instalado
- [ ] Scraper testado e funcionando
- [ ] Arquivos JSON/CSV sendo gerados
- [ ] Agendador configurado (se necess√°rio)
- [ ] API rodando (se necess√°rio)
- [ ] Integra√ß√£o N8N configurada (se necess√°rio)
- [ ] Monitoramento ativo

---

**Desenvolvido para Cam√µes Autom√≥veis** üöó  
**Vers√£o:** 2.0 Final - Otimizada e Pronta para Produ√ß√£o
